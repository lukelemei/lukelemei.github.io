<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://lukelemei.github.io</id>
    <title>浩玩技术栈</title>
    <updated>2020-03-21T15:12:33.297Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://lukelemei.github.io"/>
    <link rel="self" href="https://lukelemei.github.io/atom.xml"/>
    <subtitle>结合博主自身经验，专注分享运维技术文章！</subtitle>
    <logo>https://lukelemei.github.io/images/avatar.png</logo>
    <icon>https://lukelemei.github.io/favicon.ico</icon>
    <rights>All rights reserved 2020, 浩玩技术栈</rights>
    <entry>
        <title type="html"><![CDATA[Mysql知识梳理（一）]]></title>
        <id>https://lukelemei.github.io/post/mysql-zhi-shi-shu-li-yi/</id>
        <link href="https://lukelemei.github.io/post/mysql-zhi-shi-shu-li-yi/">
        </link>
        <updated>2020-03-21T13:48:16.000Z</updated>
        <content type="html"><![CDATA[<p><em><strong>Mysql是运维工程师的必备技能，疫情期间借此机会，重新系统化学习下Mysql数据库，以下摘林晓斌的付费专栏《Mysql实战45讲》，感兴趣的童鞋可以前往<a href="https://time.geekbang.org" title="极客时间">极客时间</a>自行购买！</strong></em></p>
<figure data-type="image" tabindex="1"><a href="https://imgchr.com/i/3UMlOs"><img src="https://s2.ax1x.com/2020/02/26/3UMlOs.md.png" alt="3UMlOs.md.png" loading="lazy"></a></figure>
<ul>
<li>上图为Mysql的逻辑架构图，可以清楚地看到 SQL 语句在 MySQL 的各个功能模块中的执行过程。</li>
<li>MySQL 可以分为 Server 层和存储引擎层两部分。</li>
<li>Server 层包括连接器、查询缓存、分析器、优化器、执行器等，涵盖 MySQL 的大多数核心服务功能，以及所有的内置函数（如日期、时间、数学和加密函数等），所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图等。</li>
<li>存储引擎层负责数据的存储和提取。其架构模式是插件式的，支持 InnoDB、MyISAM、Memory 等多个存储引擎。现在最常用的存储引擎是 InnoDB，它从 MySQL 5.5.5 版本开始成为了默认存储引擎。</li>
<li>create table 建表的时候，如果不指定引擎类型，默认使用的就是 InnoDB</li>
<li>数据库里面，长连接是指连接成功后，如果客户端持续有请求，则一直使用同一个连接。短连接则是指每次执行完很少的几次查询就断开连接，下次查询再重新建立一个。</li>
<li>一条查询语句的执行过程一般是经过连接器、分析器、优化器、执行器等功能模块，最后到达存储引擎。</li>
<li>与查询流程不一样的是，更新流程还涉及两个重要的日志模块，它们正是我们今天要讨论的主角：redo log（重做日志）和 binlog（归档日志）</li>
<li>MySQL 可以恢复到半个月内任意一秒的状态</li>
<li>mysql为了提高更新效率，采用了WAL技术，Write-Ahead Logging，它的关键点就是先写日志，再写磁盘。</li>
<li>具体来说，当有一条记录需要更新的时候，InnoDB 引擎就会先把记录写到 redo log（粉板）里面，并更新内存，这个时候更新就算完成了。同时，InnoDB 引擎会在适当的时候，将这个操作记录更新到磁盘里面<br>
<a href="https://imgchr.com/i/3UKjdx"><img src="https://s2.ax1x.com/2020/02/26/3UKjdx.md.png" alt="3UKjdx.md.png" loading="lazy"></a></li>
<li>write pos 是当前记录的位置，一边写一边后移，写到第 3 号文件末尾后就回到 0 号文件开头。checkpoint 是当前要擦除的位置，也是往后推移并且循环的，擦除记录前要把记录更新到数据文件。</li>
<li>有了 redo log，InnoDB 就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，这个能力称为 crash-safe。</li>
<li>最开始 MySQL 里并没有 InnoDB 引擎。MySQL 自带的引擎是 MyISAM，但是 MyISAM 没有 crash-safe 的能力，binlog 日志只能用于归档</li>
</ul>
<h3 id="两种日志有以下三点不同">两种日志有以下三点不同：</h3>
<ul>
<li>redo log 是 InnoDB 引擎特有的；binlog 是 MySQL 的 Server 层实现的，所有引擎都可以使用。</li>
<li>redo log 是物理日志，记录的是“在某个数据页上做了什么修改”；binlog 是逻辑日志，记录的是这个语句的原始逻辑，比如“给 ID=2 这一行的 c 字段加 1 ”。</li>
<li>redo log 是循环写的，空间固定会用完；binlog 是可以追加写入的。“追加写”是指 binlog 文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。</li>
<li>redo log 用于保证 crash-safe 能力。innodb_flush_log_at_trx_commit 这个参数设置成 1 的时候，表示每次事务的 redo log 都直接持久化到磁盘。这个参数我建议你设置成 1，这样可以保证 MySQL 异常重启之后数据不丢失。sync_binlog 这个参数设置成 1 的时候，表示每次事务的 binlog 都持久化到磁盘。这个参数我也建议你设置成 1，这样可以保证 MySQL 异常重启之后 binlog 不丢失。</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Nginx面试题]]></title>
        <id>https://lukelemei.github.io/post/nginx-mian-shi-ti/</id>
        <link href="https://lukelemei.github.io/post/nginx-mian-shi-ti/">
        </link>
        <updated>2020-03-21T13:43:24.000Z</updated>
        <content type="html"><![CDATA[<h4 id="nginx-如何优化优化">Nginx 如何优化优化</h4>
<p>1.服务优化</p>
<ul>
<li>隐藏版本号</li>
<li>修改用户和组</li>
<li>expires缓存(一般是图片)</li>
<li>日志切割</li>
<li>设置超时时间<br>
keepalive_timeout   #设置超时时间<br>
client_header_timeout  #指定请求头的超时时间<br>
client_body_timeout    #设置请求体超时时间</li>
</ul>
<ul>
<li>Gzip压缩<br>
Nginx_http_gzip_module压缩模块提供了对文件压缩的功能，以节约网站的带宽，提高用户的访问体验<br>
默认Nginx已经安装该模块<br>
gzip on    #开启gzip压缩输出<br>
gzip_buffers 4 64;   #表示申请了4个单位为64kb的内存作为压缩结果流缓存<br>
gzip_http_version 1.1  #用于设置http协议版本<br>
gzip_min_length     #设置允许页面的最小字节<br>
gzip_vary on;       #让前端的缓存服务器缓存就经过的gzip压缩页面</li>
</ul>
<ul>
<li>防盗链<br>
Nginx防盗链的原理是加入location项，用正则表达式过滤图片类型文件，对于信任的网站可以正常使用，对于不信任的网址则返回相应的错误页面</li>
</ul>
<pre><code>[root@localhost ~]# vim/usr/local/nginx/conf/nginx.conf
          location ~*\.(jpg|gif|swf)$ {
            valid_referers none blocked *.benet.com benet.com;
            if ( $invalid_referer ) {
               rewrite ^/ http://www.benet.com/error.png;
            }
         }
    ~*.(jpg|gif|swf)$: 匹配不区分大小写，以.jpg 或.gif或 .swf结尾的文件。
    valid_referers：设置信任的网站，可以正常使用图片。
    none：浏览器中refer为空的情况，就是直接在浏览器访问图片。
    blocked：浏览器中refer不为空的情况，但是值被代理或防火墙删除了，这些值不以http://或 https://开头。
    后面的网址或域名：refer包含相关字符串的网址。
    if语句：如果链接的来源域名不在valid_referers所列出的列表中， $invalid_referer 为1，则执行后面的操作，即进行重写或返回403页面。
</code></pre>
<h4 id="nginx-upsteam几种轮训方式">nginx upsteam几种轮训方式</h4>
<p><em>nginx的反向代理模块主要是基于upstream实现的，使用一般的upstream方式，其中upstream主要分为三种模式</em></p>
<ul>
<li>RR轮询: 默认的反向代理模式，用以平衡各个服务器的负载，若某个服务器宕机，会自动从轮询中剃掉。同时，可以手动指定某台服务器脱离轮询,用于离线检查</li>
<li>weight 权重: 针对服务器性能不通，用来控制服务器被访问的比例，以实现老客户访问时的快速调度</li>
<li>ip bash,主要记录了客户端IP访问的目标主机,以实现老用户访问的快速调度</li>
</ul>
<h4 id="nginx使用limit_req_zone对同一ip访问进行限流">Nginx使用limit_req_zone对同一IP访问进行限流</h4>
<pre><code>首先在nginx.conf中的http模块下配置
limit_req_zone $binary_remote_addr zone=one:10m rate=1r/s;
区域名称one(自定义)，占用空间大小为10m,平均处理请求速度不能超过每秒一次

在http模块的子模块server下配置
    location ~* .htm$ {
    limit_req zone=one burst=5  nodelay;
    proxy_pass http://backend_tomcat;
    }
burst 缓冲队列的长度
nodelay 不延迟
真正对限流起作用的就是rate=1r/s和burst=5这2个配置
</code></pre>
<h4 id="nginx-如何获取客户端的真实ip">nginx 如何获取客户端的真实IP</h4>
<p>使用forwarded-fr获取真实IP</p>
<h4 id="什么是并发-并行-阻塞-异步-同步">什么是并发、并行、阻塞、异步、同步</h4>
<ul>
<li>并发/并行: CPU在执行多个任务时的方式，并发表示同一段时间里面有多个进程在同一CPU执行，在极短的时间互相切换使人不会发觉。并行只会出现在多个CPU的情况下，表示同一时刻之内有多个进程在执行</li>
</ul>
<p>例子： 在开车的时候有个电话，必须停下车才可以接电话，接完电话继续开车，这就是并发。 如果一边开车一遍接电话，这就是并行</p>
<ul>
<li>同步/异步: 关注的是请求和响应的通讯机制，描述的是被调用方。当发出请求后，该请求是否等待结果后再返回，同步就是没有得到结果前不会返回，返回即得到请求结果。异步就是得到发出请求后就直接返回，也可能不会立即得到结果，服务得到结果后再通过通知或者回调函数等方法通知调用者</li>
</ul>
<p>例子: 去买咖啡，付了钱在前台等待咖啡制作完毕，就是同步，付了钱不在前台等待，找位置坐下，服务员送过来就是异步</p>
<ul>
<li>阻塞/非阻塞: 关注的是请求在等待结果时的状态，描述的是调用方。 阻塞就是在等待结果的时候，当前线程会被挂起，在得到结果之后返回；非阻塞则是没有得到结果之前也不会阻塞当前线程</li>
</ul>
<p>例子: 阻塞的情况就是卖咖啡的时候什么都不能做，只能挂起；非阻塞的时候就是在等咖啡的时候可以玩着手机，过一会检查咖啡是否好了</p>
<h4 id="nginx-跨域">nginx 跨域</h4>
<p>`首先我们要知道什么是跨域，跨域指的是浏览器不能执行其他网站的脚本，它是由浏览器的同源策略造成的，是浏览器对JavaScript施加的安全限制</p>
<p>举例:A页面想获取B页面资源，如果a,b页面的协议、端口、域名、子域名不同，所进行的所有访问请求都是跨域的，而浏览器一般为了安全都限制跨域请求，也就是不允许跨域请求资源。注意：跨域其实是浏览器的限制！</p>
<ul>
<li>
<p>如何解决跨域请求？<br>
Access-Control-Allow-Origin: http://api.bob.com<br>
Access-Control-Allow-Credentials: true<br>
Access-Control-Expose-Headers: FooBar<br>
Content-Type: text/html; charset=utf-8</p>
</li>
<li>
<p>Access-Control-Allow-Origin<br>
这里大概意思是允许跨域的域名，可以写一个域名，或者写* 代表所有</p>
</li>
<li>
<p>Access-Control-Allow-Credentials<br>
表示是否允许发送Cookie，默认情况下，Cookie不包括在CORS请求之中。设置为true，表示服务器明确许可，Cookie可以包含在请求中，一起发给服务器，如果服务器不需要浏览器发送的Cookie，删除该字段即可</p>
</li>
<li>
<p>Access-Control-Expose-Headers<br>
示请求头的字段 动态获取<br>
`</p>
</li>
</ul>
<h4 id="nginx-location-优先级">nginx location 优先级</h4>
<p>~ 表示执行一个正则匹配,区分大小写<br>
~* 表示执行一个正则匹配，不区分大小写<br>
^~ 表示普通字符匹配。使用前缀匹配，如果匹配，则不再匹配其他location<br>
= 进行普通字符精准匹配<br>
@ 它定义一个命名的location，使用在内部定向时，<br>
location优先级说明</p>
<p>在nginx的location和匹配中的location的顺序没有太大关系。正location表达式的类型有关。相同类型的表达式，字符串长的会优先匹配</p>
<p>等号类型(=)的优先级最高，一旦匹配成功，则不再查找其他匹配项<br>
^~ 类型表达式，一旦匹配成功，则不再查找其他匹配项<br>
正则表达式(~ ~*)的优先级次之，如果多个location的正则能匹配的话，则使用正则表达式最长的那个</p>
<h4 id="nginx-rewrite重写">nginx rewrite重写</h4>
<p>rewrite功能就是，使用nginx提供的全局变量或者自己设置的变量，结合正则表达式和标志位实现url重写及重定向。rewrite只能放在server location if中，并且只能对域名后面的除去参数外的字符串起作用</p>
<h4 id="nginx-常用的模块名称及解释">nginx 常用的模块（名称及解释）</h4>
<ul>
<li>Nginx 内置模块<br>
http_ssl_module 模块为HTTPS提供必要的支持，需要使用openssl</li>
<li>http_flv_module  通过返回以请求偏移位置开始的文件内容，该模块专门处理 在查询串中有start参数的请求, 和有预先设置到FLV头部的请求。</li>
<li>http_gzip_static_module 允许发送以“.gz”作为文件扩展名的预压缩文件，以替代发送普通文件。</li>
<li>http_stub_status_module nginx基础查询模块，可以查看连接数、请求书、header请求信息等</li>
<li>http_secure_link_module nginx安全下载模块可以给服务器文件链接添加时间戳和校验码，从而保护服务器文件不被任意下载盗用</li>
<li>http_random_index_module   可在目录中选择随机主页</li>
<li>http_realip_module   用于接受前端发来的 IP head 信息，从获取到真是的用户IP</li>
<li>http_addition_module  响应之前或者之后追加文本内容，比如想在站点底部追加一个js或者css，可以使用这个模块来实现，这个模块和淘宝开发的nginx footer模块有点类似,但是还是有不同. 这个模块需要依赖子请求，nginx footer依赖nginx写死的配置</li>
<li>http_sub_module  该模块是一个过滤器，它修改网站响应内容中的字符串，比如你想把响应内容中的‘abcdocker’全部替换成‘aaaaa‘</li>
<li>http_dav_module  该模块是一种基于 HTTP 1.1协议的通信协议。它扩展了HTTP 1.1，在GET、POST、HEAD等几个HTTP标准方法以外添加了一些新的方法，使应用程序可直接对Web Server直接读写，并支持写文件锁定(Locking)及解锁(Unlock)，还可以支持文件的版本控制</li>
<li>http_perl_module  模块用于在Perl中实现位置和变量处理程序，并将Perl调用插入SSL。需要安装perl-devel perl-ExtUtils-Embed</li>
<li>http_geoip_module  使用预编译的MaxMind数据库解析客户端IP地址，得到变量值</li>
<li>http_xslt_module  该模块是一个使用多个 XSLT stylesheets（样式表）将xml相应进行相应变换的过滤器模块。</li>
<li>http_mp4_module   主要是以 .mp4、.m4v、和.m4a为扩展名的文件， 提供伪流媒体服务端支持。</li>
</ul>
<h4 id="-第三方模块">------&gt; 第三方模块</h4>
<pre><code>headers-more-nginx-module-master   自定义请求头模块

ngx_http_substitutions_filter_module  有时候需要使用Nginx的反向代理某站点，并通过 httpsubmodule 和ngx_http_substitutions_filter_module 模块替换正文内容和URL。 官方自带的模块HttpSubModule 只能匹配1条规则，但是使用第三方模块ngx_http_substitutions_filter_module 可以匹配多条规则。

nginx_upstream_check_module-master  nginx自带是没有针对负载均衡后端节点的健康检查的，但是可以通过默认自带的ngx_http_proxy_module模块和ngx_http_upstream_module模块中的相关指令来完成当后端节点出现故障时，自动切换到健康节点来提供访问，但是还会有请求转发到后端的这台后端节点上面去

lua-nginx-module  该模块将Lua解释器或LuaJIT 2嵌入到nginx内核中，并通过cosocket和Nginx子请求将功能强大的Lua线程（又名Lua协程）集成到Nginx事件模型中。

ngx_cache_purge-master   此模块可以清理 nginx 的 FastCGI、proxy、 SCGI 和 uWSGI 的缓存

echo-nginx-module-master 提供直接在 Nginx 配置使用包括 &quot;echo&quot;, &quot;sleep&quot;, &quot;time&quot; 等指令。

ngx_devel_kit  它具有处理通用任务的功能和宏，这些任务目前没有通用代码作为核心发行版的一部分。NDK本身增加了一些从用户角度来看的功能-旨在帮助减少Nginx模块开发人员需要编写的代码。
</code></pre>
<h4 id="nginx-反向代理和正向代理区别">nginx 反向代理和正向代理区别</h4>
<ul>
<li>正向代理<br>
正向代理 是一个位于客户端和原始服务器(origin server)之间的服务器，为了从原始服务器取得内容，客户端向代理发送一个请求并指定目标(原始服务器)，然后代理向原始服务器转交请求并将获得的内容返回给客户端。客户端必须要进行一些特别的设置才能使用正向代理。就像要访问google用vpn代理翻墙去访问</li>
<li>反向代理<br>
对于客户端而言它就像是原始服务器，并且客户端不需要进行任何特别的设置。客户端向反向代理 的命名空间(name-space)中的内容发送普通请求，接着反向代理将判断向何处(原始服务器)转交请求，并将获得的内容返回给客户端，就像这些内容 原本就是它自己的一样。（用户不知道要访问真正的服务器<br>
以租房为例解释正向代理和反向代理</li>
</ul>
<p>正向代理 客户端 &lt;一&gt; 代理 一&gt;服务端</p>
<p>A(客户端)想租C(服务端)的房子,但是A(客户端)并不认识C(服务端)租不到。</p>
<p>B(代理)认识C(服务端)能租这个房子所以你找了B(代理)帮忙租到了这个房子。</p>
<p>这个过程中C(服务端)不认识A(客户端)只认识B(代理)</p>
<p>C(服务端)并不知道A(客户端)租了房子，只知道房子租给了B(代理)。</p>
<p>反向代理 客户端 一&gt;代理 &lt;一&gt; 服务端</p>
<p>A(客户端)想租一个房子,B(代理)就把这个房子租给了他。</p>
<p>这时候实际上C(服务端)才是房东。</p>
<p>B(代理)是中介把这个房子租给了A(客户端)。</p>
<p>这个过程中A(客户端)并不知道这个房子到底谁才是房东</p>
<p>他都有可能认为这个房子就是B(代理)的</p>
<p>由上的例子我们可以知道正向代理和反向代理的区别在于代理的对象不一样,正向代理的代理对象是客户端,反向代理的代理对象是服务端。</p>
<p>请陈述stub_status和sub_filter指令的作用是什么?<br>
Stub_status指令: 该指令用于了解Nginx当前状态的当前状态，如当前的活动连接，接受和处理当前读/写/等待连接的总数</p>
<p>Sub_filter指令: 它用于搜索和替换响应中的内容，并快速修复陈旧的数据</p>
<p>请列举Nginx和Apache 之间的不同点<br>
<a href="https://imgchr.com/i/30ueNq"><img src="https://s2.ax1x.com/2020/02/27/30ueNq.png" alt="30ueNq.png" loading="lazy"></a></p>
<h4 id="nginx-和lvs-区别">Nginx 和LVS 区别</h4>
<p>1.高并发连接：官方测试能够支撑5万并发连接，在实际生产环境中跑到2——3万并发连接数。<br>
2.内存消耗少：在3万并发连接数下，开启的10个nginx进程才消耗150M内存（150*10=150M）。<br>
3.配置文件非常简单：风格跟程序一样通俗易懂。<br>
4.成本低廉：nginx为开源软件，可以免费使用。而购买F5 big-ip、netscaler等硬件负载均衡交换机则需要十多万至几十万人民币。<br>
5.支持rewrite重写规则：能够根据域名、url的不同，将http请求分到不同的后端服务器群组。<br>
6.内置的健康检查功能：如果nginx proxy后端的某台web服务器宕机了，不会影响前端访问。<br>
7.节省带宽：支持gzip压缩，可以添加浏览器本地缓存的header头。</p>
<h4 id="nginx-lvs-haproxy区别">Nginx、LVS、haproxy区别</h4>
<ul>
<li>Nginx 优点</li>
</ul>
<p>工作在网络的7层之上，可以针对http应用做一些分流的策略，比如针对域名、目录结构，它的正则规则比HAProxy更为强大和灵活，这也是它目前广泛流行的主要原因之一，Nginx单凭这点可利用的场合就远多于LVS了。<br>
Nginx对网络稳定性的依赖非常小，理论上能ping通就就能进行负载功能，这个也是它的优势之一；相反LVS对网络稳定性依赖比较大。<br>
Nginx安装和配置比较简单，测试起来比较方便，它基本能把错误用日志打印出来。LVS的配置、测试就要花比较长的时间了，LVS对网络依赖比较大。<br>
可以承担高负载压力且稳定，在硬件不差的情况下一般能支撑几万次的并发量，负载度比LVS相对小些。<br>
Nginx可以通过端口检测到服务器内部的故障，比如根据服务器处理网页返回的状态码、超时等等，并且会把返回错误的请求重新提交到另一个节点，不过其中缺点就是不支持url来检测。比如用户正在上传一个文件，而处理该上传的节点刚好在上传过程中出现故障，Nginx会把上传切到另一台服务器重新处理，而LVS就直接断掉了，如果是上传一个很大的文件或者很重要的文件的话，用户可能会因此而不满。<br>
Nginx不仅仅是一款优秀的负载均衡器/反向代理软件，它同时也是功能强大的Web应用服务器。LNMP也是近几年非常流行的web架构，在高流量的环境中稳定性也很好。<br>
Nginx现在作为Web反向加速缓存越来越成熟了，速度比传统的Squid服务器更快，可以考虑用其作为反向代理加速器。<br>
Nginx可作为中层反向代理使用，这一层面Nginx基本上无对手，唯一可以对比Nginx的就只有 lighttpd了，不过 lighttpd目前还没有做到Nginx完全的功能，配置也不那么清晰易读，社区资料也远远没Nginx活跃。<br>
Nginx也可作为静态网页和图片服务器，这方面的性能也无对手。还有Nginx社区非常活跃，第三方模块也很多。</p>
<ul>
<li>Nginx 缺点</li>
</ul>
<p>Nginx仅能支持http、https和Email协议，这样就在适用范围上面小些，这个是它的缺点。<br>
对后端服务器的健康检查，只支持通过端口来检测，不支持通过url来检测。不支持Session的直接保持，但能通过ip_hash来解决。</p>
<ul>
<li>LVS 优点</li>
</ul>
<ol>
<li>抗负载能力强、是工作在网络4层之上仅作分发之用，没有流量的产生，这个特点也决定了它在负载均衡软件里的性能最强的，对内存和cpu资源消耗比较低。</li>
<li>配置性比较低，这是一个缺点也是一个优点，因为没有可太多配置的东西，所以并不需要太多接触，大大减少了人为出错的几率。</li>
<li>工作稳定，因为其本身抗负载能力很强，自身有完整的双机热备方案，如LVS+Keepalived。</li>
<li>无流量，LVS只分发请求，而流量并不从它本身出去，这点保证了均衡器IO的性能不会受到大流量的影响。</li>
<li>应用范围比较广，因为LVS工作在4层，所以它几乎可以对所有应用做负载均衡，包括http、数据库、在线聊天室等等。</li>
</ol>
<ul>
<li>LVS 缺点</li>
</ul>
<ol>
<li>软件本身不支持正则表达式处理，不能做动静分离；而现在许多网站在这方面都有较强的需求，这个是Nginx/HAProxy+Keepalived的优势所在。</li>
<li>如果是网站应用比较庞大的话，LVS/DR+Keepalived实施起来就比较复杂了，特别后面有 Windows Server的机器的话，如果实施及配置还有维护过程就比较复杂了，相对而言，Nginx/HAProxy+Keepalived就简单多了。</li>
</ol>
<ul>
<li>HAProxy优点<br>
HAProxy也是支持虚拟主机的。<br>
HAProxy的优点能够补充Nginx的一些缺点，比如支持Session的保持，Cookie的引导；同时支持通过获取指定的url来检测后端服务器的状态。<br>
HAProxy跟LVS类似，本身就只是一款负载均衡软件；单纯从效率上来讲HAProxy会比Nginx有更出色的负载均衡速度，在并发处理上也是优于Nginx的。<br>
HAProxy支持TCP协议的负载均衡转发，可以对MySQL读进行负载均衡，对后端的MySQL节点进行检测和负载均衡，大家可以用LVS+Keepalived对MySQL主从做负载均衡。<br>
HAProxy负载均衡策略非常多，HAProxy的负载均衡算法现在具体有如下8种：<br>
① roundrobin，表示简单的轮询，这个不多说，这个是负载均衡基本都具备的；<br>
② static-rr，表示根据权重，建议关注；<br>
③ leastconn，表示最少连接者先处理，建议关注；<br>
④ source，表示根据请求源IP，这个跟Nginx的IP_hash机制类似，我们用其作为解决session问题的一种方法，建议关注；<br>
⑤ ri，表示根据请求的URI；<br>
⑥ rl_param，表示根据请求的URl参数’balance url_param’ requires an URL parameter name；<br>
⑦ hdr(name)，表示根据HTTP请求头来锁定每一次HTTP请求；<br>
⑧ rdp-cookie(name)，表示根据据cookie(name)来锁定并哈希每一次TCP请求。</li>
</ul>
<h4 id="请解释nginx服务器上的master和worker进程分别是什么">请解释Nginx服务器上的Master和Worker进程分别是什么?</h4>
<p>Master进程：读取及评估配置和维持<br>
Worker进程：处理请求</p>
<p>请解释Nginx如何处理HTTP请求。</p>
<ol>
<li>三次握手后 系统内核收到请求根据端口负载均衡的分配到某个worker</li>
<li>nginx 会分配一个512byte链接内存池</li>
<li>初始化nginx的http模块并等待用户请求，假设用户在client_header_timeout指令设置的值内还没再次请求，则链接超时</li>
<li>处理用户发送请求(处理链接和处理请求还是有很大区别的，以下是处理请求操作需要校验请求头等)</li>
</ol>
<h4 id="解释下large_client_header_buffers指令设置的含义">解释下large_client_header_buffers指令设置的含义：</h4>
<p>4 8k 并不是48k nginx先会分配8k内存假设header超过第一次分配的8k 则再会分配第二个8k 也就是 16k 那么 4 8k 真正意思是 最多分配4个8k也就是32k</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Kubernetes V1.15.1搭建]]></title>
        <id>https://lukelemei.github.io/post/kubernetes-v1151-da-jian/</id>
        <link href="https://lukelemei.github.io/post/kubernetes-v1151-da-jian/">
        </link>
        <updated>2020-03-21T13:20:09.000Z</updated>
        <content type="html"><![CDATA[<h4 id="节点规划">节点规划</h4>
<ul>
<li>master：192.168.2.11</li>
<li>node1：192.168.2.22</li>
<li>node2：192.168.2.33</li>
<li>主机系统：Centos7.6</li>
<li>内核版本：4.4.216-1.el7.elrepo.x86_64<br>
(3.10内核版中有bug，会对docker和k8s造成不稳定，生产环境中建议升级内核版本)</li>
</ul>
<h4 id="前期准备">前期准备</h4>
<ul>
<li>更改主机名以及hosts解析</li>
</ul>
<pre><code>hostnamectl set-hostname master
hostnamectl set-hostname node1
hostnamectl set-hostname node2
</code></pre>
<ul>
<li>安装依赖包</li>
</ul>
<pre><code>yum install -y conntrack ntpdate ntp ipvsadm ipset jq iptables curl sysstat libseccomp wget vim net-tools git
</code></pre>
<ul>
<li>关闭防火墙 安装，清空 iptables</li>
</ul>
<pre><code>systemctl stop firewalld &amp;&amp; systemctl disable firewalld
yum -y install iptables-services &amp;&amp; systemctl start iptables &amp;&amp; systemctl enable iptables &amp;&amp; iptables -F &amp;&amp; service iptables save
</code></pre>
<ul>
<li>关闭虚拟内存</li>
</ul>
<pre><code>swapoff -a &amp;&amp; sed -i '/ swap / s/^\(.*\)$/#\1/g' /etc/fstab
安装时会检测swap是否关闭
</code></pre>
<ul>
<li>关闭 Selinux</li>
</ul>
<pre><code>setenforce 0 &amp;&amp; sed -i 's/^SELINUX=.*/SELINUX=disabled/' /etc/selinux/config
</code></pre>
<ul>
<li>调整内核参数</li>
</ul>
<pre><code>cat &gt; k8s.conf &lt;&lt; EOF
net.bridge.bridge-nf-call-iptables=1 #打开网桥转发功能
net.bridge.bridge-nf-call-ip6tables=1
net.ipv4.ip_forward=1
net.ipv4.tcp_tw_recycle=0
vm.swappiness=0
vm.overcommit_memory=1
vm.panic_on_oom=0
fs.inotify.max_user_instances=8192
fs.inotify.max_user_watches=1048576
fs.file-max=52706963
fs.nr_open=52706963
net.ipv6.conf.all.disable_ipv6=1
EOF
cp k8s.conf /etc/sysctl.d/k8s.conf
sysctl -p /etc/sysctl.d/k8s.conf
</code></pre>
<ul>
<li>设置 rsyslogd 和 systemd journald</li>
</ul>
<pre><code>持久化保存日志的目录
mkdir /var/log/journal
mkdir /etc/systemd/journald.conf.d
cat &gt; /etc/systemd/journald.conf.d/99-prophet.conf &lt;&lt;EOF
[Journal]
# 持久化保存到磁盘
Storage=persistent
# 压缩历史日志
Compress=yes
SyncIntervalSec=5m
RateLimitInterval=30s
RateLimitBurst=1000
# 最大占用空间10g
SystemMaxUse=10G
# 单个日志文件最大 200m
SystemMaxFileSize=200m
# 日志保存时间2周
MaxRetentionSec=2week
# 不将日志转发到 syslog
ForwardToSyslog=no
EOF
systemctl restart systemd-journald #重启日志进程
</code></pre>
<ul>
<li>升级内核为 4.44</li>
</ul>
<pre><code>rpm -Uvh http://www.elrepo.org/elrepo-release-7.0-3.el7.elrepo.noarch.rpm
# 安装完成后检查 /boot/grub2/grub.cfg 中对应内核 menuentry 中是否包含 initrd16 配置，如果没有，再装一次！
yum --enablerepo=elrepo-kernel install -y kernel-lt
#  设置开机从新内核启动
grub2-set-default &quot;CentOS linux (4.4.216-1.el7.elrepo.x86_64) 7 (Core)&quot;
</code></pre>
<ul>
<li>kube-proxy开启ipvs的前置条件</li>
</ul>
<pre><code>modprobe br_netfilter
cat &gt; /etc/sysconfig/modules/ipvs.modules &lt;&lt;EOF
#!/bin/bash
modprobe -- ip_vs
modprobe -- ip_vs_rr
modprobe -- ip_vs_wrr
modprobe -- ip_vs_sh
modprobe -- nf_conntrack_ipv4
EOF
chmod 755 /etc/sysconfig/modules/ipvs.modules &amp;&amp; bash
/etc/sysconfig/modules/ipvs.modules &amp;&amp; lsmod | grep -e ip_vs -e nf_conntrack_ipv4
</code></pre>
<ul>
<li>安装 Docker</li>
</ul>
<pre><code>yum install -y yum-utils device-mapper-persistent-data lvm2

yum-config-manager \
 --add-repo \
 http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo
 
yum update -y &amp;&amp; yum install -y docker-ce
mkdir -p /etc/systemd/system/docker.service.d
systemctl daemon-reload &amp;&amp; systemctl restart docker &amp;&amp; systemctl enable docker
</code></pre>
<ul>
<li>Kubeadm</li>
</ul>
<pre><code>cat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=Kubernetes
baseurl=http://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64
enabled=1
gpgcheck=0
repo_gpgcheck=0
gpgkey=http://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg
http://mirros.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg
EOF

yum -y install kubeadm-1.15.1 kubectl-1.15.1 kubelet-1.15.1
systemctl enable kubelet.service
</code></pre>
<ul>
<li>初始化主节点</li>
</ul>
<pre><code>#初始化master节点时，kubernetes会拉取相关镜像
 生成kubeadm配置文件，修改配置文件里的images下载源、是否允许Master允许业务Pod、网络配置信息
kubeadm config print init-defaults &gt; kubeadm.conf

vi kubeadm.conf
//修改默认kubeadm初始化参数如下
imageRepository: registry.cn-hangzhou.aliyuncs.com/google_containers
kubernetesVersion: v1.15.1
nodeRegistration:
  taints:
  - effect: PreferNoSchedule
    key: node-role.kubernetes.io/master
localAPIEndpoint:
  advertiseAddress: 192.168.2.11   # 这里甜master节点ip
networking:
  dnsDomain: cluster.local
  podSubnet: 10.244.0.0/16
  serviceSubnet: 172.18.0.0/16

# 使用自定义配置拉取 images
kubeadm config images pull --config kubeadm.conf
</code></pre>
<p><strong>注意：拉取镜像如果不设置，默认会从谷歌服务器拉取，因国内无法访问谷歌，可采取重新tag都方法获取镜像。<br>
国内k8s镜像站：registry.cn-hangzhou.aliyuncs.com/google_container</strong></p>
<pre><code>例如：
docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/kube-scheduler:v1.15.1 k8s.gcr.io/kube-scheduler:v1.15.1
</code></pre>
<ul>
<li>获取的镜像如下：</li>
</ul>
<pre><code>每个节点都需要以下镜像
k8s.gcr.io/kube-apiserver:v1.15.1
k8s.gcr.io/kube-controller-manager:v1.15.1
k8s.gcr.io/kube-scheduler:v1.15.1
k8s.gcr.io/kube-proxy:v1.15.1
k8s.gcr.io/pause:3.1
k8s.gcr.io/etcd:3.3.10
k8s.gcr.io/coredns:1.3.1
</code></pre>
<ul>
<li>部署master节点</li>
</ul>
<pre><code>kubeadm init --config=/root/kubeadm.conf --experimental-upload-certs | tee kubeadm-init.log
</code></pre>
<p>部署成功后，会有如下提示：</p>
<pre><code>Your Kubernetes control-plane has initialized successfully!

To start using your cluster, you need to run the following as a regular user:

  mkdir -p $HOME/.kube
  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
  sudo chown $(id -u):$(id -g) $HOME/.kube/config

You should now deploy a pod network to the cluster.
Run &quot;kubectl apply -f [podnetwork].yaml&quot; with one of the options listed at:
  https://kubernetes.io/docs/concepts/cluster-administration/addons/

Then you can join any number of worker nodes by running the following on each as root:

kubeadm join 192.168.2.11:6443 --token abcdef.0123456789abcdef \
    --discovery-token-ca-cert-hash sha256:7b0e84998468fdf580eedade1e3297a947a0c72a0310f4489f501443223c1079
</code></pre>
<ul>
<li>初始化完成后，设置相关环境变量</li>
</ul>
<pre><code>mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config
</code></pre>
<ul>
<li>加入node节点</li>
</ul>
<pre><code>在每个节点上，直接运行如下命令
kubeadm join 192.168.2.11:6443 --token abcdef.0123456789abcdef \
    --discovery-token-ca-cert-hash sha256:7b0e84998468fdf580eedade1e3297a947a0c72a0310f4489f501443223c1079
</code></pre>
<ul>
<li>部署flannel网络插件</li>
</ul>
<pre><code>wget https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml
#此网站需要科学上网才能打开
kubectl create -f kube-flannel.yml
#如果创建失败，可以手动下载镜像
quay.io/coreos/flannel:v0.12.0-amd64
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Docker Haproxy搭建PXC负载均衡]]></title>
        <id>https://lukelemei.github.io/post/docker-haproxy-da-jian-pxc-fu-zai-jun-heng/</id>
        <link href="https://lukelemei.github.io/post/docker-haproxy-da-jian-pxc-fu-zai-jun-heng/">
        </link>
        <updated>2020-03-17T13:54:14.000Z</updated>
        <content type="html"><![CDATA[<h4 id="pxc集群信息">pxc集群信息</h4>
<pre><code>pxc-node1 172.30.0.100 3306
pxc-node2 172.30.0.101 3306
pxc-node3 172.30.0.102 3306
</code></pre>
<h4 id="拉取docker镜像">拉取docker镜像</h4>
<pre><code>dcoker pull haproxy:1.9.3 
</code></pre>
<ul>
<li>创建数据卷挂载目录</li>
</ul>
<pre><code>mkdir -p /pxc/haproxy
</code></pre>
<h4 id="配置文件">配置文件</h4>
<p>在/pxc/haproxy目录下，新建haproxy.cfg</p>
<pre><code>global
	#工作目录
	chroot /usr/local/etc/haproxy
	#日志文件，使用rsyslog服务中local5日志设备（/var/log/local5），等级info
	log 127.0.0.1 local5 info
	#守护进程运行
	daemon
 
defaults
	log	global
	mode	http
	#日志格式
	option	httplog
	#日志中不记录负载均衡的心跳检测记录
	option	dontlognull
    #连接超时（毫秒）
	timeout connect 5000
    #客户端超时（毫秒）
	timeout client  50000
	#服务器超时（毫秒）
    timeout server  50000
 
#监控界面	
listen  admin_stats
	#监控界面的访问的IP和端口
	bind  0.0.0.0:8888
	#访问协议
    mode        http
	#URI相对地址
    stats uri   /dbs
	#统计报告格式
    stats realm     Global\ statistics
	#登陆帐户信息
    stats auth  admin:abc123456
#数据库负载均衡
listen  proxy-mysql
	#访问的IP和端口
	bind  0.0.0.0:3306
    #网络协议
	mode  tcp
	#负载均衡算法（轮询算法）
	#轮询算法：roundrobin
	#权重算法：static-rr
	#最少连接算法：leastconn
	#请求源IP算法：source 
    balance  roundrobin
	#日志格式
    option  tcplog
	#在MySQL中创建一个没有权限的haproxy用户，密码为空。Haproxy使用这个账户对MySQL数据库心跳检测
    option  mysql-check user haproxy
    
    server pxc-node1 172.30.0.100:3306 check weight 1 maxconn 2000 
    server pxc-node2 172.30.0.101:3306 check weight 1 maxconn 2000 
    server pxc-node3 172.30.0.102:3306 check weight 1 maxconn 2000 

</code></pre>
<ul>
<li>创建镜像</li>
</ul>
<pre><code>docker run -d -p 4001:8888 -p 4002:3306 --name haproxy --net host -v /pxc/haproxy/:/usr/local/etc/haproxy haproxy:1.9.3
</code></pre>
<h4 id="数据库中创建haproxy账号">数据库中创建haproxy账号</h4>
<pre><code>创建haproxy 密码为空
create user 'haproxy'@'%' identified by ''; 
</code></pre>
<h4 id="验证">验证</h4>
<p>打开http://192.168.10.100:8888/dbs 查看监控页面<br>
看到三个pxc节点的状态均为up，即配置成功<br>
<img src="https://s1.ax1x.com/2020/03/17/8aKrQI.jpg" alt="8aKrQI.jpg" loading="lazy"></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[PXC集群搭建]]></title>
        <id>https://lukelemei.github.io/post/pxc-ji-qun-da-jian/</id>
        <link href="https://lukelemei.github.io/post/pxc-ji-qun-da-jian/">
        </link>
        <updated>2020-03-17T13:52:38.000Z</updated>
        <content type="html"><![CDATA[<h4 id="介绍">介绍</h4>
<p>PXC是Percona XtraDB Cluster的缩写，是一种具有高可用性和高扩展性的MySQL开源集群。它集成了Percona Server和Percona XtraBackup，同时采用了Codership Galera库。</p>
<h4 id="优点">优点</h4>
<p>1.准同步复制<br>
2.多个可同时读写节点，可实现写扩展，较分片方案更进一步<br>
3.自动节点管理<br>
4.数据严格一致<br>
5.服务高可用</p>
<h4 id="缺点">缺点</h4>
<p>1.只支持innodb引擎<br>
2.所有表都要有主键<br>
3.所有的写操作都将发生在所有节点上，存在写扩大问题<br>
4.加入新节点，开销大。需要复制完整的数据。</p>
<h4 id="搭建">搭建</h4>
<ul>
<li>采用docker形式部署</li>
<li>拉取镜像</li>
</ul>
<pre><code>docker pull percona/percona-xtradb-cluster:5.7
</code></pre>
<ul>
<li>重新tag</li>
</ul>
<pre><code>为了方便，这里重新tag下
docker tag percona/percona-xtradb-cluster:5.7 pxc
</code></pre>
<ul>
<li>创建数据卷</li>
</ul>
<pre><code>docker volume create v1
docker volume create v2
docker volume create v3
</code></pre>
<ul>
<li>创建网络</li>
</ul>
<pre><code>docker network create --subnet=172.30.0.0/24 pxc-network
</code></pre>
<ul>
<li>启动容器<br>
注意等第一个容器启动，确保可连接之后再依次启动第二第三容器</li>
</ul>
<pre><code> docker run -d -p 33306:3306 -v v1:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=root -e CLUSTER_NAME=pxc --name=pxc-node1 --net=pxc-network --ip=172.30.0.100 pxc
 
 docker run -d  -p 33307:3306 -v v1:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=root -e CLUSTER_NAME=pxc --name=pxc-node2 -e CLUSTER_JOIN=pxc-node1  --net=pxc-network --ip=172.30.0.101 pxc
 
 docker run -d  -p 33308:3306 -v v3:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=root -e CLUSTER_NAME=pxc --name=pxc-node3 -e CLUSTER_JOIN=pxc-node1  --net=pxc-network --ip=172.30.0.102 pxc
 
</code></pre>
<h4 id="验证">验证</h4>
<ul>
<li>启动容器：<br>
<a href="https://imgchr.com/i/8UU7MF"><img src="https://s1.ax1x.com/2020/03/17/8UU7MF.md.jpg" alt="8UU7MF.md.jpg" loading="lazy"></a></li>
<li>查看集群的状态</li>
</ul>
<pre><code>show status like '%wsrep%';
</code></pre>
<figure data-type="image" tabindex="1"><a href="https://imgchr.com/i/8UU5GV"><img src="https://s1.ax1x.com/2020/03/17/8UU5GV.md.jpg" alt="8UU5GV.md.jpg" loading="lazy"></a></figure>
<ul>
<li>创建数据库测试，三个节点都可同步成功<br>
<a href="https://imgchr.com/i/8Udd9P"><img src="https://s1.ax1x.com/2020/03/17/8Udd9P.jpg" alt="8Udd9P.jpg" loading="lazy"></a></li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Binlog数据恢复的几种方法]]></title>
        <id>https://lukelemei.github.io/post/binlog-shu-ju-hui-fu-de-ji-chong-fang-fa/</id>
        <link href="https://lukelemei.github.io/post/binlog-shu-ju-hui-fu-de-ji-chong-fang-fa/">
        </link>
        <updated>2020-03-11T00:58:22.000Z</updated>
        <content type="html"><![CDATA[<h4 id="binlog的模式">binlog的模式</h4>
<ul>
<li>Statement Level：Mysql5.7.7之前的版本默认的模式。基于sql语句复制，只会存储sql，不会存储数据，因此无法进行数据恢复，生产环境一般不用此模式</li>
<li>Row Level：Mysql5.7.7之后的版本默认的模式。基于行的复制，并且会将每一条的数据变化记录到日志文件中。</li>
<li>Mixed：混合模式</li>
</ul>
<p>查询模式命令</p>
<pre><code>show variables like 'binlog_format';
mysql&gt; show variables like 'binlog_format';
+---------------+-------+
| Variable_name | Value |
+---------------+-------+
| binlog_format | ROW   |
+---------------+-------+
1 row in set (0.00 sec)
</code></pre>
<h4 id="数据的解析">数据的解析</h4>
<ul>
<li>将binlog二进制文件解析成sql语句的过程</li>
</ul>
<h4 id="恢复工具介绍">恢复工具介绍</h4>
<ul>
<li>
<p>正向恢复：</p>
<ul>
<li>mysqlbinlog<br>
利用工具将插入的sql解析成反向的sql语句</li>
</ul>
</li>
<li>
<p>反向恢复</p>
<ul>
<li>binlog-rollback</li>
<li>MyFlash</li>
</ul>
</li>
<li>
<p>延迟从库</p>
</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Django Web开发入门（一）]]></title>
        <id>https://lukelemei.github.io/post/django-web-kai-fa-ru-men-yi/</id>
        <link href="https://lukelemei.github.io/post/django-web-kai-fa-ru-men-yi/">
        </link>
        <updated>2020-03-10T12:04:15.000Z</updated>
        <content type="html"><![CDATA[<h4 id="安装">安装</h4>
<pre><code>pip3 install django==2.2.11 指定版本安装
pip3 install django 不指定版本即安装最新版本，目前是3.0.4
在python中导入django模块，能正确打印出版本，即安装成功
PyDev console: starting.
Python 3.7.3 (v3.7.3:ef4ec6ed12, Mar 25 2019, 16:52:21) 
[Clang 6.0 (clang-600.0.57)] on darwin
import django
print(django.VERSION)
(2, 2, 11, 'final', 0)
</code></pre>
<h4 id="建立项目">建立项目</h4>
<ul>
<li>命令:</li>
</ul>
<pre><code>django-admin startproject myproject 项目名称
项目建成后，目录树如下
├── manage.py
└── myproject
    ├── __init__.py
    ├── settings.py
    ├── urls.py
    └── wsgi.py
</code></pre>
<h4 id="建立应用">建立应用</h4>
<ul>
<li>命令：</li>
</ul>
<pre><code>python manage.py startapp myapp 应用名称
应用建成后，目录树如下：
.
├── __init__.py
├── admin.py
├── apps.py
├── migrations
│   └── __init__.py
├── models.py
├── tests.py
└── views.py
</code></pre>
<h4 id="编写页面应用代码">编写页面应用代码</h4>
<ul>
<li>路由响应函数</li>
<li>通过url将用户http访问与路由函数进行绑定</li>
<li>在myproject/urls.py文件中，加入应用的urls.py的引用</li>
</ul>
<h4 id="范例演示">范例演示</h4>
<p>演示一个简单的页面</p>
<ul>
<li>第一步：在myproject/myapp/views.py中建立路由响应函数</li>
</ul>
<pre><code>from django.shortcuts import render
from django.http import HttpResponse
# Create your views here.
def welcome(request):
	return HttpResponse(&quot;&lt;h1&gt;welcome to my first web!&lt;/h1&gt;&quot;)
</code></pre>
<ul>
<li>第二步：通过URL将用户的http访问与路由函数绑定<br>
在myproject/myapp 目录中，新建一个urls.py文件，管理应用的所有url映射</li>
</ul>
<pre><code>from django.conf.urls import url
from . import views

urlpatterns = [
	url(r'',views.welcome,name='first-url'),
]
</code></pre>
<ul>
<li>第三步：在myproject/urls.py文件中，添加一行，声明对应用myapp的urls.py文件的引用</li>
</ul>
<pre><code>from django.contrib import admin
from django.urls import path
from django.conf.urls import url  #本行为新增
from django.conf.urls import include  #本行为新增
urlpatterns = [
	url(r'^app/',include('myapp.urls')),  #本行为新增
    path('admin/', admin.site.urls),
]
</code></pre>
<h4 id="启动页面访问">启动页面访问</h4>
<p>通过内置的web服务器访问页面，仅用于开发测试环境</p>
<ul>
<li>命令：</li>
</ul>
<pre><code>python manage.py runserver 0:8002
</code></pre>
<p>如无报错，页面显示如下：<br>
<a href="https://imgchr.com/i/8ifL79"><img src="https://s2.ax1x.com/2020/03/10/8ifL79.md.jpg" alt="8ifL79.md.jpg" loading="lazy"></a></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[玩转 Docker（二）]]></title>
        <id>https://lukelemei.github.io/post/wan-zhuan-dockerer/</id>
        <link href="https://lukelemei.github.io/post/wan-zhuan-dockerer/">
        </link>
        <updated>2020-03-05T12:47:13.000Z</updated>
        <content type="html"><![CDATA[<h4 id="docker-网络">Docker 网络</h4>
<ul>
<li>应用对外访问</li>
</ul>
<pre><code>-P:在49000-49900之间，随机映射一个端口
-p：手动指定端口，宿主机的3303:3000（外部）
</code></pre>
<ul>
<li>容器间网络通信</li>
</ul>
<pre><code>使用 --link参数
创建一个数据库容器：
docker run -d –namemysqldb mysql:5.6
创建一个web容器并和数据库容器建立连接：
docker run -d –name Webapp–p 8000:8080 –link mysqldb:MySQL tomcat
上边的MySQL别名就类似dns解析的方式，我给这个容器起了个别名叫MySQL，我就通过这个别名就可以找到对应的这个mysqldb容器
mysqldb容器和web容器建立互联关系。
</code></pre>
<h4 id="dockerfile">Dockerfile</h4>
<p>Dockerfile是一个文本格式的配置文件，用户可以使用Dockerfile快速创建自定义镜像。</p>
<ul>
<li>参数解释</li>
</ul>
<pre><code>FROM
格式：FROM&lt;image&gt;或FROM&lt;image&gt;:&lt;tag&gt;。
解释：FROM是Dockerfile里的第一条指令（必须是），后面跟有效的镜像名（如果该镜像你的本地仓库没有则会从远程仓库Pull取）。然后后面的其它指令FROM的镜像中执行。

MAINTAINER
格式：MAINTAINER &lt;name&gt;
解释：指定维护者信息。

RUN
格式：RUN &lt;command&gt;或 RUN[&quot;executable&quot;, &quot;param1&quot;, &quot;param2&quot;]。
解释：运行命令，命令较长使可以使用\来换行。推荐使用上面数组的格式

CMD
格式：
CMD [&quot;executable&quot;,&quot;param1&quot;,&quot;param2&quot;] 使用 exec 执行，推荐方式；
CMD command param1 param2 在 /bin/sh 中执行，提供给需要交互的应用；
CMD [&quot;param1&quot;,&quot;param2&quot;] 提供给ENTRYPOINT的默认参数；
解释：
CMD指定容器启动是执行的命令，每个Dockerfile只能有一条CMD命令，如果指定了多条，只有最后一条会被执行。如果你在启动容器的时候也指定的命令，那么会覆盖Dockerfile构建的镜像里面的CMD命令。

ENTRYPOINT
格式：
   ENTRYPOINT [&quot;executable&quot;, &quot;param1&quot;,&quot;param2&quot;]
   ENTRYPOINT command param1 param2（shell中执行）。
解释：和CMD类似都是配置容器启动后执行的命令，并且不可被 docker run 提供的参数覆盖。
每个 Dockerfile 中只能有一个 ENTRYPOINT，当指定多个时，只有最后一个起效。ENTRYPOINT没有CMD的可替换特性，也就是你启动容器的时候增加运行的命令不会覆盖ENTRYPOINT指定的命令。
所以生产实践中我们可以同时使用ENTRYPOINT和CMD，
例如：
ENTRYPOINT [&quot;/usr/bin/rethinkdb&quot;]
CMD [&quot;--help&quot;]

USER
格式：USER daemon
解释：指定运行容器时的用户名和UID，后续的RUN指令也会使用这里指定的用户。

EXPOSE
格式：EXPOSE&lt;port&gt; [&lt;port&gt;...]
解释：设置Docker容器内部暴露的端口号，如果需要外部访问，还需要启动容器时增加-p或者-P参数进行分配。

ENV
格式：ENV 
ENV =&lt;value&gt; ...
解释：设置环境变量，可以在RUN之前使用，然后RUN命令时调用，容器启动时这些环境变量都会被指定

ADD
格式：
   ADD &lt;src&gt;... &lt;dest&gt;
ADD [&quot;&quot;,... &quot;&quot;]
解释：将指定的复制到容器文件系统中的
所有拷贝到container中的文件和文件夹权限为0755,uid和gid为0
如果文件是可识别的压缩格式，则docker会帮忙解压缩

VOLUME
格式：VOLUME [&quot;/data&quot;]
解释：可以将本地文件夹或者其他container的文件夹挂载到container中。

WORKDIR
格式：WORKDIR/path/to/workdir
解释：切换目录，为后续的RUN、CMD、ENTRYPOINT 指令配置工作目录。
可以多次切换(相当于cd命令)，
也可以使用多个WORKDIR 指令，后续命令如果参数是相对路径，则会基于之前命令指定的路径。例如

WORKDIR /a
WORKDIR b
WORKDIR c
RUN pwd
则最终路径为 /a/b/c。
ONBUILD
ONBUILD 指定的命令在构建镜像时并不执行，而是在它的子镜像中执行

ARG
格式：ARG&lt;name&gt;[=&lt;default value&gt;]
解释：ARG指定了一个变量在docker build的时候使用，可以使用--build-arg =来指定参数的值，不过如果构建的时候不指定就会报错。
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[玩转 Docker（一）]]></title>
        <id>https://lukelemei.github.io/post/wan-zhuan-dockeryi/</id>
        <link href="https://lukelemei.github.io/post/wan-zhuan-dockeryi/">
        </link>
        <updated>2020-03-05T12:39:30.000Z</updated>
        <content type="html"><![CDATA[<h4 id="虚拟化与docker">虚拟化与docker</h4>
<ul>
<li>
<p>虚拟化定义：虚拟化是一种资源管理技术，是将计算机的各种实体资源，如服务器、网络、内存及存储等，予以抽象、转换后呈现出来，打破实体结构间的不可切割的障碍，使用户可以比原本的配置更好的方式来应用这些资源。这些资源的新虚拟部分是不受现有资源的架设方式，地域或物理配置所限制。一般所指的虚拟化资源包括计算能力和数据存储。</p>
</li>
<li>
<p>系统虚拟化，Hypervisor Virtualization，全虚拟化。在 Host 中通过 Hypervisor 层实现安装多个 GuestOS，每个 GuestOS 都有自己的内核，和主机的内核不同，GuestOS 之间完全隔离。</p>
</li>
<li>
<p>容器虚拟化，Operating System Virtualization ，使用 Linux 内核中的 namespaces 和 cgroups 实现进程组之间的隔离。是用内核技术实现的隔离，所以它是一个共享内核的虚拟化技术。</p>
</li>
<li>
<p>容器虚拟化没有 GuestOS，使用 Docker 时下载的镜像，只是为运行 App 提供的一个依赖的环境，是一个删减版本的系统镜像。一般情况下系统虚拟化没有容器虚拟化的运行效率高，但是系统安全性高很多。</p>
</li>
</ul>
<h4 id="核心概念">核心概念</h4>
<ul>
<li>镜像： 镜像就是一个只读的模板</li>
<li>容器：运行应用。可以把容器看成一个精简版的Linux环境</li>
<li>仓库：集中存放镜像文件的地方。</li>
</ul>
<h4 id="docker常用命令-镜像">Docker常用命令-镜像</h4>
<ul>
<li>获取镜像：docker pull</li>
<li>查看镜像列表：docker images</li>
<li>查看镜像信息：docker inspect</li>
<li>查找镜像：docker search</li>
<li>删除镜像：docker rmi</li>
<li>创建镜像：docker commit</li>
<li>导出镜像：docker save [images] &gt; [name.tar]（可以导出多个镜像合成一个tar包）</li>
<li>导入镜像：docker load &lt; xxx.tar</li>
<li>上传镜像：docker push</li>
</ul>
<h4 id="docker常用命令-容器">Docker常用命令-容器</h4>
<ul>
<li>启动容器：docker run –name -h hostname</li>
</ul>
<pre><code>docker run -d -P nginx

-d运行在后台

-P 代表随机映射

nginx 镜像的名称
</code></pre>
<ul>
<li>
<p>停止容器：docker stop CONTAINER ID</p>
</li>
<li>
<p>查看容器：docker ps -a -l</p>
</li>
<li>
<p>进入容器：docker exec | docker attach |nsenter</p>
</li>
<li>
<p>删除容器：docker rm</p>
</li>
<li>
<p>查看容器日志：docker logs CONTAINER ID</p>
</li>
</ul>
<h4 id="docker-仓库">Docker 仓库</h4>
<ul>
<li>公有仓库：在互联网上，任何人都可以访问
<ul>
<li><a href="https://hub.docker.com/">docker hub</a> 官方仓库</li>
<li><a href="https://dev.aliyun.com/search.html">阿里云</a></li>
<li><a href="https://c.163yun.com/hub#/m/home/">网易云</a></li>
<li><a href="https://hub.daocloud.io/">DaoCloud</a></li>
</ul>
</li>
<li>私有仓库：个人或者组织的私有仓库，只有有访问权限的人才可访问</li>
<li>开源企业级镜像仓库平台：<a href="https://goharbor.io">Harbor</a></li>
</ul>
<h4 id="镜像加速站">镜像加速站</h4>
<ul>
<li>官方默认的镜像仓库在国外，拉取镜像太慢，可配置国内加速器进行加速</li>
<li>国内加速站点</li>
</ul>
<pre><code>https://registry.docker-cn.com

http://hub-mirror.c.163.com

https://3laho3y3.mirror.aliyuncs.com

http://f1361db2.m.daocloud.io

https://mirror.ccs.tencentyun.com
</code></pre>
<ul>
<li>加速配置范例</li>
</ul>
<pre><code>没有daemon.json文件，则需新建
vim /etc/docker/daemon.json 
写入
{
  &quot;registry-mirrors&quot;: [&quot;https://registry.docker-cn.com&quot;]
}
systemctl daemon-reload
systemctl restart docker
镜像加速可以设置多个，之间用逗号隔开
</code></pre>
<h4 id="docker-网络">Docker 网络</h4>
<p>Docker网络目前有四种网络模式：Bridge模式、Host模式、Container模式、None模式</p>
<ul>
<li>Bridge：容器启动后默认的网络模式。</li>
</ul>
<pre><code>当Docker进程启动时，会在主机上创建一个名为Docker0的虚拟网桥，此主机上启动的Docker容器默认会连接到这个虚拟网桥上。虚拟网桥的工作方式和物理交换机相似，这样主机上的所有容器就通过交换机连在了一个二层网络中。从docker0子网中分配一个IP给容器使用，并设置docker0的IP地址为容器的默认网关。在主机上创建一对虚拟网卡veth pair设备，Docker将veth pair设备的一端放在新创建的容器中，并命名为eth0(容器内部网卡)，另一端在放在主机中，以vethxxx这样类似的名称命名，并将这个网络设备加入到docker0网桥中。可以使用brctl show命令查看
</code></pre>
<ul>
<li>Host：容器和宿主机共用一个网络</li>
</ul>
<pre><code>如果启动容器的时候使用host模式，那么这个容器将不会获取一个独立的Network Namespace，而是和宿主机共用一个Network Namespace(这里和我们平常使用的虚拟机的仅主机模式相似)。容器将不会虚拟出自己的网卡，配置自己的IP等，而是使用宿主机的IP和端口。但是，容器的其他方面，如文件系统、系统进程等还是和宿主机隔离的
</code></pre>
<ul>
<li>Container: 新建容器和已有容器共用一个网络，不和宿主机共享网络</li>
</ul>
<pre><code>这个模式指定新创建的容器和已经存在的容器共享一个Network Namespace，而不是和宿主机共享。新创建的容器也不会自己创建网卡，IP等。而是和一个指定的容器共享IP、端口范围等。同样，两个容器除了网络方面，其他的还都是属于隔离。两个容器的进程可以通过宿主机的lo网卡设备进行通信
</code></pre>
<ul>
<li>None：容器只用自己的独有网络</li>
</ul>
<pre><code>使用none模式，Docker容器拥有自己的Network Namespace，但是，并不为Docker容器进行任何网络配置。也就是说，这个Docker容器没有网卡、IP、路由等信息。需要我们自己为Docker容器添加网卡、配置IP等
</code></pre>
<h4 id="docker-数据管理">Docker 数据管理</h4>
<ul>
<li>数据卷</li>
</ul>
<pre><code>数据卷是一个可供容器或多个容器使用的特殊目录，它绕过UFS，可以提供很多有用的特性 （相当于NFS）,其目的是用于数据的持久化。

1. 数据卷可以在容器之间共享和重用
2. 对数据卷的修改会马上生效
3. 对数据卷的更新，不会影响镜像
4. 数据卷默认会一直存在，即使容器被删除

数据卷的使用，类似于NFS挂载，镜像中的被指定为挂载点的目录中会隐藏掉，能显示看 的是挂载的数据卷
</code></pre>
<ul>
<li>数据卷相关命令：</li>
</ul>
<pre><code>创建数据卷：docker volume create data
查看所有数据卷：docker volume ls
查看指定数据卷信息：docker volume inspect data
挂载数据卷：docker run -v参数进行指定
数据卷的默认权限为rw（可读写），如要改变需要手动指定，例如改为ro只读：docker run -d –name app1-it -v /webapp:/root/webapp:ro ubuntu bash
</code></pre>
<ul>
<li>数据卷容器<br>
命名的容器挂载数据卷，其他容器通过挂载这个容器实现数据共享，挂载数据卷的这个容器成为数据卷容器。</li>
</ul>
<pre><code>Example:

创建数据卷容器db1

docker run -d –name db1 -v/dbdata -ti ubuntu bash

创建容器db2与db1共享dbdata的数据

docker run -d –name db2 –volumes-from db1 -ti ubuntu bash

在容器db1和容器db2任意一个容器修改dbdata的内容，在两个容器内均生效


</code></pre>
<p>用数据卷容器备份和恢复数据</p>
<ul>
<li>备份：</li>
</ul>
<pre><code>[root@tcy1 Documents]# docker run --volumes-from volume-test1 -v $(pwd):/backup --name volume-test6 nginx tar cvf /backup/backup.tar /data
tar: Removing leading `/' from member names
/data/
/data/test/
/data/testSyc

命令解释：

①、首先利用nginx镜像创建了一个名字为volume-test6的容器；
②使用 --volumes-from volume-test1参数让volume-test6容器挂载volume-test1容器中的data数据卷；
③使用 -v $(pwd):/backup参数来挂载本地的当前目录到volume-test1容器的/backup目录。
④volume-test1容器启动后，使用tar cvf /backup/backup.tar /data命令来将 /data下内容备份为容器内的/backup/backup.tar,即宿主机当前目录下的backup.tar。
</code></pre>
<ul>
<li>恢复：</li>
</ul>
<pre><code>将数据恢复到一个容器:
①创建一个带有数据卷datarecover的容器recover，
[root@tcy1 Documents]# docker run -v /datarecover --name recover nginx
②创建另一个新的容器，挂载数据卷datarecover，然后解压备份文件到所挂载的容器卷中。
[root@tcy1 tcy]# docker run --volumes-from recover -v $(pwd):/backup nginx tar xvf /backup/backup.tar
data/
data/test/
data/testSyc
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[CentOS6.X 安装zabbix-agent]]></title>
        <id>https://lukelemei.github.io/post/centos6x-an-zhuang-zabbix-agent/</id>
        <link href="https://lukelemei.github.io/post/centos6x-an-zhuang-zabbix-agent/">
        </link>
        <updated>2020-03-03T13:32:13.000Z</updated>
        <content type="html"><![CDATA[<p><strong>1.安装zabbix-agent</strong></p>
<p>rpm -ivh zabbix-agent-4.0.14-1.el7.x86_64.rpm</p>
<p><strong>2.修改</strong>**/etc/zabbix/zabbix_agentd.conf文件：**</p>
<p><strong>执行如下命令</strong></p>
<p>sed -i 's/Server=127.0.0.1/Server=35.1.196.100/g' /etc/zabbix/zabbix_agentd.conf</p>
<p>sed -i 's/ServerActive=127.0.0.1/ServerActive=35.1.196.100/g' /etc/zabbix/zabbix_agentd.conf</p>
<p>执行完成后，打开文件检查下 Server和ServerActive两个选项的IP是否已经修改为35.1.196.100</p>
<p><strong>3.启动服务并设置为开启启动</strong></p>
<p>service zabbix-agent start 启动服务</p>
<p>chkconfig zabbix-agent on 开启启动</p>
<p><strong>4.如果已经开启防火墙，需在防火墙放行10050端口，未开启防火墙请忽略</strong></p>
<p>放行端口命令：<br>
iptables -A INPUT -p tcp --dport 10050 -j ACCEPT<br>
<strong>5.关闭selinux</strong></p>
<p>执行命令：setenforce 0(立即生效)</p>
<p>并修改配置文件/etc/selinux/config 将selinux设置为disabled(重启后，永久生效)</p>
]]></content>
    </entry>
</feed>